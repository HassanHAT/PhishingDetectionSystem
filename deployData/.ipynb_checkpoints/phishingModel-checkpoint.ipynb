{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1_KcrhYosEl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Enhanced feature extraction function\n",
        "def extract_features(texts):\n",
        "    features = pd.DataFrame({\n",
        "        'length': [len(text) for text in texts],\n",
        "        'word_count': [len(text.split()) for text in texts],\n",
        "        'has_urgency': [1 if re.search(r'\\b(urgent|immediately|now|quick|action required|expire)\\b', text.lower()) else 0 for text in texts],\n",
        "        'has_money': [1 if re.search(r'\\b(win|prize|cash|free|bonus|reward|\\$|money|dollar|million|billion)\\b', text.lower()) else 0 for text in texts],\n",
        "        'has_link': [1 if re.search(r'http|www|\\.com|\\.net|\\.org|click|\\.link|bit\\.ly|goo\\.gl', text.lower()) else 0 for text in texts],\n",
        "        'special_char_count': [len(re.findall(r'[!@#$%^&*()_+\\-=\\[\\]{};:\\'\"\\\\|,.<>\\/?]', text)) for text in texts],\n",
        "        'has_greeting': [1 if re.search(r'^dear|hello|hi |greetings|valued customer', text.lower()) else 0 for text in texts],\n",
        "        'has_threat': [1 if re.search(r'\\b(suspend|close|terminate|verify|confirm|account|security|alert)\\b', text.lower()) else 0 for text in texts]\n",
        "    })\n",
        "    return features\n",
        "\n",
        "# Custom transformer wrapper\n",
        "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, texts): return extract_features(texts)\n",
        "\n",
        "# Load and prepare data\n",
        "sms = pd.read_csv('dataDeployment/PhishingData.csv', encoding='latin-1')\n",
        "\n",
        "sms = sms.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
        "\n",
        "sms = sms.dropna(subset=['text','label'])\n",
        "\n",
        "sms['label'] = sms['label'].map({'ham': 0,'spam': 1})\n",
        "\n",
        "# Drop rows not mapping\n",
        "sms = sms.dropna(subset=['label'])\n",
        "\n",
        "# Convert label to integer\n",
        "sms['label'] = sms['label'].astype(int)\n",
        "\n",
        "\n",
        "# Create pipeline with enhanced parameters\n",
        "pipeline = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', TfidfVectorizer(max_features=5000, ngram_range=(1,3), stop_words='english')),\n",
        "        ('manual', FeatureExtractor())])),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=25,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1))\n",
        "])\n",
        "\n",
        "# Train model with evaluation\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    sms['text'], sms['label'], test_size=0.2, random_state=42, stratify=sms['label'])\n",
        "pipeline.fit(X_train, Y_train)\n",
        "\n",
        "# Save model\n",
        "with open('phishingModel.pkl', 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "# Evaluate model\n",
        "predY = pipeline.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(Y_test, predY))\n"
      ]
    }
  ]
}